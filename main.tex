\documentclass{llncs}
%\documentclass[10pt, conference, compsocconf]{IEEEtran}

% From ESORICS'13 CFP
% Submitted papers should be at most 16 pages (using 10-point font), excluding 
% the bibliography and well-marked appendices, and at most 20 pages total.

\usepackage{listings}
\usepackage{url}

\usepackage{amssymb}
\usepackage[usenames]{color}
\definecolor{lightred}{rgb}{1,0.8,0.8}
\newcommand{\todo}[1]{\colorbox{red}{\textcolor{white}{\sffamily\bfseries\scriptsize TODO}} \textcolor{red}{#1} \textcolor{red}{$\blacktriangleleft$}}


\title{Architectures for Inlining Security Monitors in Web Applications}

\author{Jonas Magazinius \and Daniel Hedin \and Andrei Sabelfeld}
\institute{Chalmers University of Technology, Gothenburg, Sweden}
%%%%%%%%%%%%%%%% Schedule %%%%%%%%%%%%%%%%%%%%%%%%
\if 0
March 28 - paper shipped
March 27 - final polish
March 25 - instantiation
March 22 - intro and conclusions
March 22 - the bulk of instantiation
March 22 - implementation
March 21 - architecture
March 20 - related work
March 12 - implementation half-way
March 11 - architecture first pass
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\lstdefinelanguage{lang}
{
 sensitive=true,
 morecomment=[l]{--},
 morestring=[b]'',
basicstyle=\ttfamily,
fontadjust=true
}

\lstdefinelanguage{langsmall}
{
 sensitive=true,
 morecomment=[l]{--},
 morestring=[b]'',
basicstyle=\ttfamily\footnotesize,
fontadjust=true
}
\lstset{language=lang}

% comment out for the final version
\pagestyle{plain}

\begin{document}


\maketitle

% comment out for the final version
\thispagestyle{plain}

\begin{abstract}
Securing JavaScript in the browser is an open and challenging
problem. Code from pervasive third-party JavaScript libraries exacerbates the
problem because it is executed with the same privileges as the code
that uses the libraries.
%
An additional complication is that the different stakeholders have
different interests in the security policies to be enforced
in web applications.
%
This paper focuses on securing JavaScript code by \emph{inlining}
security checks in the code before it is executed.
%
We achieve great flexibility in the deployment options by considering
security monitors implemented as security-enhanced JavaScript interpreters.
%
%A key ingredient to open up for such flexibility is security monitoring in the form of a
%security monitor for JavaScript, written itself in JavaScript.
We propose architectures for inlining security monitors for JavaScript: via
browser, via web proxy, and via suffix proxy (web service). 
%
Being parametric in the monitor itself,
the architectures provide freedom in the choice of where the monitor is
injected, allowing to serve the interests of the different stake
holders: the users, code developers, code
integrators, as well as the system and network administrators.
%
We report on experiments that demonstrate successful deployment of a JavaScript
information-flow monitor with the different architectures.
\end{abstract}


% \begin{IEEEkeywords}
% Web Security; Polyglot; Injection; Cross-domain.
% \end{IEEEkeywords}








% 1-2 pages
\section{Introduction}
\label{sec:intro}
JavaScript is at the heart of what defines the modern
browsing experience on the web. JavaScript enables dynamic and interactive
web pages as they are experienced by the users. Glued together,
JavaScript code from different sources provides
a rich execution platform. Reliance on third-party code is
pervasive~\cite{Nikiforakis+:CCS12}, with the range of included code from
format validation snippets, to helper
libraries as jQuery, to helper services as Google Analytics, and to fully-fledged services as
Google Maps and Yahoo!\@ Maps.

\paragraph{Securing JavaScript}
Securing JavaScript in the browser is an open and challenging
problem. Third-party code inclusion exacerbates the
problem. The \emph{same-origin policy (SOP)}, enforced by the modern
browsers, allows free communication to the Internet origin of a given web page 
while it
places some restrictions on communication to Internet domains
outside the origin. However, once third-party code is
included in a web page, it is executed with the same privileges as the code
that uses the libraries. This gives rise to a number of attack possibilities,
such as location
hijacking, behavioral tracking, leaking cookies, and sniffing browsing history~\cite{Jang+:CCS10}. 

\paragraph{Security policy stakeholders}
An additional complication is that the different stakeholders have
different interests in the security policies to be enforced
in web applications. 
%
\emph{Users} might demand stronger guarantees than those
offered by SOP when it is not desired that sensitive information leaves
the browser. This makes sense in such popular web applications as
password-strength checkers and loan
calculators.
%
\emph{Code developers} clearly have the interest in protecting the
secrets associated with the web application. For example, they might
allow access to the first-party cookie to code from third-party
services, like Google (this is needed for the proper functioning of
such services
as Google Analytics), but under the condition that no sensitive part
of the cookie is leaked to the third party.
%
\emph{Code integrators} might have different levels of trust to the
different integrated components, perhaps depending on the origin. It
is desirable to invoke different protection mechanisms for the
different code that is integrated into the web application.
For example, an e-commerce web site might include jQuery from a trusted
web site without protection while it might load advertisement scripts
with the monitor on. 
%
Finally, \emph{system and network administrators} also have a
stake in the security goals. It might be desirable to configure the
system and/or network so that certain users are protected to a larger
extent or communication to certain web sites is restricted to a larger
extent than to the others.  

\paragraph{Secure inlining for JavaScript}
This paper proposes a novel approach to securing JavaScript in web
applications in the presence of multiple stakeholders.
%
We focus on securing JavaScript code by \emph{inlining}
security checks in the code before it is executed.
%
A key feature
of our approach is focusing on security monitors implemented as
security-enhanced JavaScript interpreters, written in JavaScript
themselves. This, seemingly bold, approach leverages two-fold
flexibility. First, having complete information about a given
execution, security-enhanced JavaScript interpreters are able to
enforce fine-grained security policies such as \emph{information-flow
security}~\cite{Sabelfeld:Myers:JSAC}. Second, because the monitor/interpreter is written itself in
JavaScript, we achieve great flexibility in the deployment options.

\paragraph{Architectures for inlinig security monitors}
As our main contribution,
we propose architectures for inlining security monitors for JavaScript: via
browser, via web proxy, and via suffix proxy (web service). 
%
Being parametric in the monitor itself,
the architectures provide freedom in the choice of where the monitor is
injected, allowing to serve the interests of the different stake
holders: the users, code developers, code
integrators, as well as the system and network administrators.

We note that our approach is general: it applies to arbitrary security
monitors, implemented as JavaScript interpreters. The 
 Narcissus~\cite{Narcissus} project provides a baseline JavaScript
 interpreter written in JavaScript, an excellent starting
 point for supporting versatile security policies.

Our evaluation of the architectures explores the relative security
considerations.
When introducing reference monitoring, Anderson~\cite{Anderson:72}
identifies the following principles:
(i) the monitor must be tamperproof (\emph{monitor integrity}),
(ii) the monitor must be always invoked (\emph{complete
  mediation}~\cite{Saltzer:Schroeder:TCB}), and
(iii) the monitor must be small enough to be subject to correctness
analysis (\emph{small trusted computing base
  (TCB)}~\cite{Saltzer:Schroeder:TCB,DBLP:dblp_conf/sosp/Rushby81}). Overall,
the key requirements often considered in the context of monitoring are 
that the monitor must enforce the desired security policy
(\emph{soundness}) and that the monitor is transparent to the
applications (\emph{transparency}). Note the relation of
the soundness to Anderson's principles: while the principles do not
automatically imply soundness, they facilitate establishing soundness. 
Transparency requirements are often in place for reference monitors to
ensure that no new behaviors are added by monitors for any programs, and no
behaviors are removed by monitors when the
original program is secure in the first place.

Since the architectures are parametric in the actual monitor, we can
often draw on the properties of the monitor itself to guarantee the
above requirements. It is essential for soundness and
transparency that the monitor itself supports them. Monitor integrity,
complete mediation, and small TCB are of particular focus in our security
considerations for the architectures because the choice of the architecture results in
different implications for the security and transparency of the
deployed monitor.

\paragraph{Instantiation}
In order to illustrate the usefulness of the approach, we present an
instantiation of the architectures to enforce secure information flow
in JavaScript. Information-flow control for JavaScript allows tracking
fine-grained security policies for web applications. Typically,
information sources  and sinks are given sensitivity labels, for
example, corresponding to the different Internet origins. The goal of
information-flow enforcement is to prevent \emph{explicit flows}, via
direct information propagation by assignment commands, as well as
\emph{implicit flows} via the control flow in the program.

Our focus on information flow is justified by
the nature of the JavaScript attacks from the empirical
studies~\cite{Jang+:CCS10,Nikiforakis+:CCS12} that demonstrate the current security
practices fail to  prevent 
location
hijacking, behavioral tracking, leaking cookies, and sniffing browsing
history. Jang et al. ~\cite{Jang+:CCS10} report on both explicit and
implicit flows exploited in the empirical studies.
%
In addition, inlining by security-enhanced interpreting is a
particularly suitable choice for tracking information flow in
JavaScript, because alternative approaches to inlining suffer from
scalability problems, as discussed in Section~\ref{sec:related}. 

Our instantiation results demonstrate how to deploy
\emph{JSFlow}~\cite{Hedin:Sabelfeld:CSF12,JSFlow}, secure information-flow
monitor for JavaScript by Hedin et al., via
browser, via web proxy, and via suffix proxy (web service).
%
We report on security and performance experiments that demonstrate successful deployment of a JavaScript
information-flow monitor with the different architectures.


% A growing number of web pages provide not only content, but services to their
% users. In order to provide the service the provider requires the user to
% provide potentially sensitive information such as user credentials, and payment
% information. For such pages it is in the interest of the user that the
% sensitive information is only disclosed to the intended recipient.  Today, no
% browsers offer such guarantees. However, modern browsers allow the
% functionality of the browser to be enriched via \emph{extensions}. 


%\paragraph{Third-party code integration}
%\label{sec:mash}

%Describe mashups, difficulties in mashup security and information flows in mashups.

%4 pages 
\section{Architectures}
\label{sec:arch}

This section presents the different architectures for inlining
security monitors. We motivate each architecture by scenarios of
intended usage, describe the details of the architectures, report on
security considerations as well as the pros and cons for each choice.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Browser extension}

Many websites require the user to provide sensitive information, e.g., user
credentials, or payment information. It lies in the interest of the user to
ensure the security of the sensitive information.  Modern browsers allow for
the functionality of the browser to be enriched via \emph{extensions}. By
deploying the security monitor via a browser extension it is possible to enforce
properties not normally offered by browsers.  Regardless of whether the user is
private or corporate, browser extensions provide a simple 
install-once deployment method.


\paragraph{Description}

A browser extension is a program that is installed into the browser in order to
change or enrich the functionality of the browser.  The basic idea behind
deploying via an extension is to replace the JavaScript engine with the monitor.
(Recall that we consider only monitors that function as interpreters.)

Even though the internal JavaScript engine cannot actually be replaced the same
effect can be achieved by turning off the standard JavaScript engine, and have
the extension traverse the page when loaded and execute the JavaScript scripts
using the monitor. 
In addition to this, the extension must register the monitor as the target of
all events to ensure that the event handlers are run by the monitor. Failing to
do so will not compromise security; since the internal engine is turned off
the event handler would simply not run, preventing the loaded page from functioning
properly.

The most common extension implementation language is JavaScript. Given that
the monitor is written in JavaScript it is a simple matter to embed the 
monitor in an extension.
This method was pioneered by Zaphod~\cite{Zaphod}, a
FireFox extension, that replaces the standard JavaScript engine with the
experimental Narcissus~\cite{Narcissus} engine.


\paragraph{Security considerations}

The integrity of the method is guaranteed by virtue of the fact that the
JavaScript engine is turned off and all scripts are interpreted by the monitor.
Hence, the scripts are not active; rather, they are passed as data to the
monitor, and are only able to influence the execution environment implemented
by the monitor and not the general execution environment of the monitor itself.
Since all scripts are executed using the monitor complete mediation is implied.
In addition, this also implies that the deployment method is sound given that
the monitor is sound. 

As described above, browser extension are installed into the browser. In order
to be able to enrich the functionality of the browser, the extensions run with
the same privileges as the browser. This entails that the monitor will be
running with elevated privileges. Compared to the other methods of deployment
this means that a faulty monitor not only jeopardizes the property enforced by
the monitor, but might jeopardize the integrity of the entire browser.

\paragraph{Pros and cons}

Since the extension is installed on locally in the browser of the user, it has
the benefit of giving the user direct control over what security policies to 
enforce on the browsed pages without relying on and trusting other parties.

The \emph{Document Object Model} (DOM)~\cite{DOM2} provides the tree model of HTML
documents used in browsers. The DOM is a complex, richly linked tree structure,
which offers many challenges.  One example of such a feature, that can be
handled with relative ease compared to other methods of deployment, is
\lstinline{innerHTML}. \lstinline{innerHTML} is a property on all DOM objects,
that allows the text representation of the object to be changed. Any such
change causes the content of the object to be changed by parsing the changed
property. For other deployment methods this means that the value written to
\lstinline{innerHTML} must be validated, and possibly changed before the write
is allowed to occur --- even though scripts added using \lstinline{innerHTML}
are not executed, event handlers might still be run.
%
For the extension based deployment this is not a problem.  Since the standard
JavaScript execution engine is turned off it is safe to write to the
\lstinline{innerHTML} property. The write will trigger the parser to rebuild
the content of the node, but no scripts will be executed, and the result can be
handled in a manner analogous to the scripts on a loading page.

Additionally, the extension is entirely independent of the method of transport,
since the extension can tell the browser to download the resource. Since the 
browser performs the operation the result
is indistinguishable from the standard operation of the browser, and, unlike other 
methods of deployment, it is unimportant whether the scripts
are referenced using HTTP or HTTPS.

Whether the requirements of conservativeness and transparency can be met
depends on when the scripts are executed and that all functionality provided by
the browser can be implemented by the monitor.

However, some features remain challenging for the extension deployment method.
First, consider the order in which scripts are executed.  When web pages are
loaded, the scripts of the pages are executed as they are encountered while
parsing the web page. This means that the DOM tree of the page might not have
been fully constructed when the scripts execute.  For scripts that interact
with the DOM tree this is important, in particular if the script injects nodes
into the tree. Differences in the state of the DOM tree can be detected by 
scripts at execution time. Hence, to guarantee conservativeness and transparency 
the execution of scripts must occur at the same times in the DOM tree construction
as they would have in the unmodified browser. With some effort this can be achieved
using DOM mutation events.

Another challenge pertaining to conservativeness and transparency is that some
functionality provided by the browser might be difficult or expensive to
provide.  One example of this is \lstinline{document.write}. The semantics of
\lstinline{document.write} is loosely specified~\cite{DOM:LVL2} saying that
\lstinline{document.write} writes a string into the current position of the
document.  Intuitively, \lstinline{document.write} writes into the character
stream that is fed to the HTML parser, which, for obvious reason can have
drastic effects on the parsing of the page. For security reasons extensions are
prohibited from calling \lstinline{document.write}. Hence, when run via an
extension the monitor cannot easily provide the full functionality of
\lstinline{document.write}.  Consider the following example, where
\lstinline{document.write} is used inside a div element.

\begin{lstlisting}[language=langsmall]
<div><script>document.write('</div><div>');</script></div>
\end{lstlisting}

The result is two div elements, rather than the original one. Since the write
takes place during the parsing of the page, the end tag written by
\lstinline{document.write} is matched with the initial div tag, and the written
start tag is matched with the final end tag. In order to implement
\lstinline{document.write} the monitor would have to take the interaction with the
between the content written by \lstinline{document.write}, the already parsed parts
of the page and the remaining page into account. In essence, the monitor would
have to reimplement the parsing process.  However, the practical use of
\lstinline{document.write} is limited; the typical use case is to inject scripts
into the page while loading. Such cases can be relatively easily identified
from the string passed as a parameter, and the intended behavior can be
implemented by the monitor.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Web proxy}
\label{sec:arch-web}
%\todo{Daniel: I'm not sure about the story how the secret info is in the browser}
%\todo{Jonas: addressed by removing the intranet stuff}
In a corporate setting, it is essential for a company to protect 
sensitive information pertaining to the company, as well as their employees. 
Meanwhile, employees are using the web browser for accessing untrusted content on 
the Internet. Naturally, it is in the interest of the company to ensure that 
the sensitive information is not accessible outside the domain of the company.
In this distributed setting, a \emph{web proxy} is a convenient way of delivering 
the security monitor to all clients with little effort. 

A web proxy is also appealing to a private user, as it includes the monitor in all browsed pages without modifying 
the browser itself. By configuring the browser to use a web proxy, the user can ensure the security 
of sensitive data.

\paragraph{Description}
All modern browsers support using proxies to relay all requests through a proxy.
A proxy specific to relaying HTTP requests is referred to as a web proxy.
The web proxy acts as a man-in-the-middle, making 
requests on behalf of the client. In the process, the proxy can
modify both the request and the response. 
The opportunity to rewrite the response is crucial for this architecture.
A web proxy is a convenient way to rewrite the response to include 
the monitor in each page. Modifying the response makes the method more 
intrusive to the HTML content, but less intrusive to the user's browser. 

%\todo{Strong wording; any. Later is in order to be effective is used}
For the monitor to provide security guarantees, all scripts bundled with 
the page must be executed by the monitor. The scripts can either be inline, 
i.e., included as part of the HTML page, or external, i.e., referenced in the 
HTML page to be downloaded from an external source.
Apart from including the monitor in all browsed pages, all inline and external 
scripts must be identified and rewritten by the web proxy to direct execution to the monitor.
%\todo{A call to the monitor hard to understand - better use 'use the monitor to execute'?}
This is achieved by wrapping all JavaScript source code, whether inline or 
external, to be interpreted and executed by the monitor.
Different rewriting rules apply depending on whether the 
requested content is JavaScript, i.e., external, or HTML, i.e., inline. 
%\todo{Wrapped hard to understand}
For external 
JavaScript resources, containing only JavaScript, the entire response is rewritten to use the monitor to execute, whereas 
for HTML the web proxy has to identify and wrap all occurrences of inline 
JavaScript, both script-tags and event handlers.


\paragraph{Security considerations}

As opposed to a browser extension, that replaces the 
JavaScript engine, the monitor will be executed by the engine of the browser, in the context of the page. Naturally 
this is the same context in which all scripts bundled with the 
page are normally executed. The web proxy must ensure that they are all executed within the 
monitored context. This effort must continue as the monitor executes. 
Various JavaScript features, such as 
\lstinline{document.write}, allow an arbitrary string to be 
interpreted and rendered as HTML. Any scripts present in the string will be 
executed upon interpretation. The monitor must account for this and again rewrite 
the string to direct execution to the monitor. Failing to do so, script code will execute 
along-side the monitor, thereby bypassing it. 
Complete mediation is achieved given that all requests are relayed through the proxy 
and all occurrences of JavaScript within the page are rewritten to direct execution to the monitor.
%\todo{Jonas: reword slightly}

Special consideration is required for secure HTTP connections (HTTPS). In an HTTPS 
connection, a certificate containing the public key of the target domain is sent 
along with the response. The response is encrypted using the private key of the target 
domain and decrypted with the public key contained in the certificate. The 
certificate is issued by a certificate authority (CA)
that validates the certificate by signing the public key. Given that the user 
trusts the CA, it can also trust that the public key belongs 
to the target domain, and that the response has not been modified in transit.
This poses a challenge for a web proxy designed exactly to modify the response. The solution 
is for the proxy to act as a CA by generating a
new certificate for the target domain on-the-fly, and sign the 
public key of the certificate with the private key of the proxy. Naturally, 
the proxy must be trusted by the user, either by adding the key to 
the user's list of trusted CAs, or having the key signed by a CA that the user trusts.



\paragraph{Pros and cons}
%\todo{Mass config is used; even chalmers uses images, i.e., nothing is configured per machine anyhow - browser independence is really
%the key?}
The main benefit of using a web proxy 
compared to a browser extension is that the implementation is browser independent. The 
rewriting technique is the same regardless of the browser used. Hence, there is no 
need to adapt the web proxy to suit a particular browser, allowing 
the users their choice of browser.
Neither is it intrusive to the browser, as the user is not required to modify the 
browser in order to take advantage of security benefits. 

How the proxy is 
deployed determines the users' influence over 
the enforced policies.
In a corporate environment the web proxy is likely to be 
administered centrally to apply the same policy for all users. When deployed by 
an individual user it is more likely to be installed locally on the user's own machine.
If deployed locally, the user has full influence over 
policies, while for a remotely deployed proxy,
whether the policy is user-specific is 
in the hands of the proxy administrator. 


%Typically a web proxy relays and applies the monitor to all browsed pages, 
%trusted or not. With a browser extension a user can
%configure certain trusted web pages to run unmonitored for performance reasons.
%\todo{the power of configuring the monitor depends on the stakeholder and the }


%\todo{explain what locally means?}


\subsection{Suffix proxy (service)}
\label{sec:arch-suffix}


For trusted web sites, a user of a proxy service may not want to disclose
sensitive information, e.g., passwords or cookies, to the provider of the service.
Still, for untrusted web sites the user wants the increased security provided 
by the proxy.
A \emph{suffix proxy} particularly suits a user who wants to run certain untrusted 
pages monitored, but not include the monitor in trusted pages.


A proxy service may provide specific policies applied only to a few 
particular web sites. In this case, relaying requests to other web sites is an 
unnecessary waste of resources. It would be beneficial to the service provider to be
able to control precisely which web sites will be relayed through the proxy. 
This is not possible in a web proxy, that covers all requests, but a suffix proxy 
provides the means to do so.



\paragraph{Description}
A \emph{suffix proxy} is a specialized web proxy, with a different approach to relaying the request. 
The web proxy serves as a foundation for the suffix proxy, as they have much in common.
Instead of the common practice of configuring the browser to relay all requests through the web proxy,
the suffix proxy takes advantage of the domain name system (DNS) to redirect the request to it.
Wildcard domain names allow all requests to any subdomain of the domain name to resolve to a single domain name, 
i.e., in DNS terms \emph{*.proxy.domain $\Rightarrow$ proxy.domain}.
Typically, the user navigates to a 
web application associated with the proxy and enters the target URL, e.g., \url{http://google.com/search?q=proxy}, in 
an input field. To direct the request to the proxy, the target domain name is altered
by appending the domain name of the proxy, making the target domain a subdomain of the proxy domain, e.g., \url{http://google.com.proxy.domain/search?q=proxy}. 
The browser is then navigated to the modified URL.
The suffix proxy is set up so
that all requests to any subdomain of the proxy domain are directed to the proxy domain. 
A web application on the proxy domain is set up to listen for such subdomain requests.
When a request for a subdomain is registered, it is intercepted by the web application.
The web application strips the proxy domain from the URL, leaving the original target URL, 
and makes the request on behalf of the client. As in the case of the web proxy, 
relaying the request to the target URL gives the suffix proxy an opportunity to modify and 
include the monitor in the response.

Like the web proxy, the suffix proxy must ensure that all script bundled with a 
page is executed by the monitor. The procedure to rewrite script is much the same as the one
detailed in Section~\ref{sec:arch-web}. Apart from that, the URLs of links and 
resources referring to content outside the target domain must also be rewritten to point to the suffix proxy. 
Otherwise the content to will not be requested through the monitor which will 
prevent it from being rewritten.


In the suffix proxy, not only the content is rewritten
but also the headers of the incoming request and the returned response.
Certain headers, like the \emph{Host} and \emph{Referrer} header of the request, includes the 
modified domain name and need to be rewritten to make the proxy transparent. In 
the response headers like the \emph{Location} contains the unmodified target URL and 
need to be rewritten to include the monitor domain. 

%\todo{refer back to previous section, the same rules apply}

%The latter implies that apart from rewriting scripts within a page, all URLs to 
%external resources, i.e., to origins outside the scope of the original origin, 
%must be rewritten to include the domain of the proxy. This ensures that all 
%resources associated with the page are loaded through the proxy.

% and the domain of the proxy needs to 
%be inlined in all external requests. 




\paragraph{Security considerations}

A consequence of modifying the domain name is that the domain of the
target URL and the modified URL no longer matches, making them two 
separate origin as per the same-origin policy. This implies that all information in 
the browser specific to the target origin, e.g., cookies and local storage, 
are no longer associated with the modified origin, and vice versa. This results 
in a clean separation between the proxied and unproxied content.  

Another interesting consequence of altering the domain name, also relating to 
the same-origin policy, is the concept of domain relaxing. Modern web browsers 
allow relaxing of the same-origin policy for subdomains. Documents from different subdomains of the same 
domain can relax their domains by setting the \lstinline{document.domain} attribute
to their common domain. In doing so, they set aside the restrictions of the 
same-origin policy and can freely access each others resources across subdomains. 
Since the principle behind the suffix proxy is to make the target domain a subdomain of the proxy domain, two 
domains loaded via the proxy, each relaxing their domain to the domain of the 
proxy, can access each others resources across domains.
This is devastating for monitors that rely on the same-origin policy to enforce 
separation between origins. However, the flexibility of disabling the same-origin
policy opens up for monitors whose policies are aimed
at replacing the same-origin policy. 
For such usage, the suffix proxy can effectively disable the same-origin 
policy by adding a JavaScript snippet that sets the \lstinline{document.domain} property
to the proxy domain. 
%This way, the effectiveness of the policy 
%can be tested without modifying the browser.
%\todo{Daniel: yes, if expanded a bit}
%\todo{Jonas: Does the last sentence make sense?}


Recall from the previous section the rather complex procedure required to add HTTPS support.
Implementing support for HTTPS is easier in the suffix proxy compared to the web proxy. 
Given that the suffix proxy builds on DNS wildcards, it is sufficient to issue a certificate
for all subdomains of the proxy domain, e.g., \url{*.proxy.domain}. Such a 
certificate is valid for all target URLs relayed through the proxy.
The main benefit of wildcard certificates is that the user can browse HTTPS pages. 
%The drawback is that the user must trust the monitor to correctly verify the 
%certificate of the page.

\paragraph{Pros and cons}

While sharing a common foundation, there are several differences between a 
suffix proxy compared to a traditional web proxy. The differences lie, not in 
how the monitor is included in the page, but in the way the proxy is 
addressed. A consequence of the use of wildcard domain names is that the suffix proxy requires 
heavier rewriting than the web proxy in order to capture all requests. On the other 
hand, it helps in managing HTTPS requests, that is complicated in the web proxy.
Another questionable consequence is that it allows for web sites to relax the 
same-origin policy. From a monitor perspective this can be devastating under the wrong circumstances, 
while beneficial under other.

Another significant difference is that the suffix proxy lets the user and the 
service provider decide which pages to proxy on a per-domain basis, making it 
more general than a traditional web proxy that covers all requests. 
Contrary to the web proxy, the suffix proxy can be set up to only relay a few selected 
web sites, whereas requests for other web sites are redirected to their original 
addresses. This can both reduce the load on the proxy service, as well as decrease the 
overhead for the end user, thus benefiting both the user and the service provider.
For a user, deciding whether to apply the monitor or not is as simple as browsing 
to an alternate URL.

One beneficial difference is that the suffix proxy does not require any 
configuration and leaves the browser completely unchanged. The user can take
advantage of the security benefits without being concerned with the integrity 
of the browser.

%\todo{Integration stuff missing from intro? Or did I read too fast?}
\subsection{Integrator}
\label{sec:arch-integrator}
%The mashup integrator includes the monitor and decides which JavaScript should 
%run within the monitor. (Don't mention sandbox.) You're done.
%\begin{itemize}
%\item- No setup
%\item- Not intrusive to the browser
%\item- Not general
%\item- Deliberately intrusive to HTML
%\item- Integrator configuration, no user control
%\item- Run independent part of the code outside the monitor, possible performance gains
%\end{itemize}

As discussed earlier, today's
 web pages make extensive use of third-party code to add features 
and functionality to the page. The code is retrieved from external resources in 
the form of JavaScript libraries. The third-party code is considered to be part 
of the document and is executed in the same context as any other script 
included in the document. Executing the code in the context of the page gives the code full access to all the information 
of the page, including sensitive information such as form data and cookies. 
Granting such access requires that the code integrator must 
trust the library not to abuse this privilege. To a developer, an appealing alternative 
is to run untrusted code in the monitored context, while running trusted code outside of the 
monitor. 

\paragraph{Description}
Integrator-driven monitor inclusion is suitable for an integrating web page 
that makes use of third-party code.
The security of the information contained on the web 
page relies not only on the web page itself, but also on the security of all 
included libraries. To protect against malicious or compromised libraries, 
an integrator can execute part of, or all of the code in the monitor.
The code executing outside of the monitor is trusted with full access to the 
sensitive information in the page, and the untrusted code will be executed 
by the monitor, restricted from accessing the information.
This can be achieved by manually including the monitor in the page and loading the 
third-party code either through the suffix proxy, or from cached rewritten 
versions of the code. %The suffix proxy will rewrite the 
%response to direct execution of the library to the monitor. 
This approach allows for a well defined, site specific, policy specification.
The monitor is setup and configured with policies best suiting the need of the 
site. 


One important aspect of integrator-driven monitor inclusion is the interaction 
between trusted and untrusted code. 
The trusted code executing outside the monitor can interact with the code 
executed in the monitor. This way, the 
the trusted code can share specific non-sensitive information with the library, 
that the library requires to execute. There are different means of introducing this 
information to the monitor. The most rudimentary solution is to evaluate 
expressions in the monitor, containing the information in a serialized form.
The monitor can also provide an API for reading and writing variables, or 
calling functions in the monitor. This simplifies the process and is less error 
prone. An even more advanced solution is to have a set of shared variables
that are bi-directionally reflected from one context to the other when the 
their values are updated.


\paragraph{Security considerations}
%\todo{sharing information between real code and monitored code if automatic is a security problem, must be done manually}
%\todo{none of the security considerations from previous section apply}
%\todo{two libraries loaded, one trusted the other one untrusted, the trusted can mess with the monitored code}
%\todo{Jonas: need help defining the security considerations}

Despite the fact that the integrator is using the suffix proxy, none of the 
respective security considerations apply. The same-origin policy has no effect 
on requesting libraries through the proxy. The only consequence is that the library
will be rewritten so that it will be executed by the monitor.

One security consideration that arises is the implication of sharing information between the 
trusted and untrusted code. It might be appealing to simplify sharing of 
information between the two by reflecting a set of shared variables of one into the other.
However, automatically 
reflecting information from one context to the other, will 
have severe security implications. If the trusted code depend on a 
shared variable, the untrusted code can manipulate the value to control the
execution.
If the trusted code is required to share information 
with the untrusted code, such as giving access to non-sensitive information, it 
must be done by manually introducing it in the monitored context.

It should be noted that since the trusted code is running along side the monitor, 
it can access and manipulate the state of the monitor and thereby the state of 
the untrusted code. It is impossible for the monitored code to protect against 
such manipulation.

\paragraph{Pros and cons}

This developer-centric approach gives the integrator full control over the 
configuration of the monitor and the policies to enforce. From the perspective of a user this 
approach is not intrusive to the browser, requires no setup or configuration, 
and provides additional security for the user's sensitive information. However, 
it also limits the user's control over which policies are applied to user information. 

Compared to the suffix proxy, integrator driven monitor 
inclusion is deliberately intrusive to the HTML code. Such specialized use of the suffix 
proxy allows a developer to specify precisely which code will be subject to 
monitoring, making the approach even more general. 
Since a monitor typically introduces a runtime overhead this approach can also 
result in performance gains compared to running all code monitored. Especially 
if the trusted code is computation heavy.

As previously stated, sharing information 
between trusted and untrusted code in a secure manner requires manual interaction. 
This implies that the developer must to some degree understand the inner workings of the monitor
and the implications of interacting with the monitor.


% 2-3 pages 
\section{Implementation}
\label{sec:impl}

%\todo{Daniel: may I suggest we replace the pros and cons with implementation challenges}
%Describe features and drawbacks with each implementation.
%For each deployment option, we describe how it is implemented and show how the integrity of the monitor
%and complete mediation are achieved.
This section details our implementations of the architectures
from the previous section. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Browser extension}

The browser extension is a Firefox extension based on Zaphod~\cite{Zaphod}. All
in all the extension is around 1000 lines of JavaScript and XUL code.
When loaded the extension first turns off the standard JavaScript engine by
disallowing JavaScript and listens for the \lstinline{DOMContentLoaded} event.  The
\lstinline{DOMContentLoaded} event is fired as soon as the DOM tree construction is
finished.  On this event the DOM tree is traversed twice. The first traversal
checks every node for event handlers, e.g., onclick, and registers the monitor
to handle them. The second traversal looks for JavaScript script nodes.  For
each found script node, the source is downloaded using XHR if needed, and the
monitor is used to execute the script.

As discussed above, the downside of this method is that it breaks
conservativeness and transparency, since the scripts all execute after the DOM
tree has been constructed. It is possible to regain transparency by using DOM
\lstinline{MutationEvent}~\cite{DOM3Event} instead of the \lstinline{DOMContentLoaded} event.  The idea is to listen
to any addition of script nodes to the DOM tree under the construction, and
execute the script on addition.  However, due to performance reasons the DOM
Mutation events are deprecated, and are being replaced with DOM \lstinline{MutationObserver}~\cite{DOM4}. 
It is unclear whether the \lstinline{MutationObserver} can be used to
provide transparency, since events are grouped together, i.e., the mutation
observer will not necessarily get an event each time a script is added, but one
event covering all script additions.

However, the exact order of loading is not standardized and differs between
browsers. This forces scripts to be independent of such differences. Thus,
using the method of executing scripts on the \lstinline{DOMContentLoaded} event is not
necessarily a problem in practice. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Web proxy}

%\begin{itemize}
%\item Proxy implemented in NodeJS
%\item- rewrite all or nothing, problem with passing configuration to proxy
%\item DOM parsing to find scripts, compared to regular expressions
%\item difficult to identify all contexts (SVG, CSS and PDF can be rewritten, not flash)
%\item rewriting of JavaScript
%\end{itemize}

The web proxy is implemented as an HTTP-server. As the 
proxy receives a request it extracts the target URL and in turn requests the 
content from the target. Before the response is delivered to the client, it is 
rewritten based on its content-type. Each content-type related to JavaScript is 
rewritten, e.g., \emph{text/html}, \emph{text/javascript}, or \emph{text/json}. 
Since only content that can contain JavaScript is of interest, other 
content-types are simply passed through to the user. In HTML, where 
JavaScript is embedded in the code, the monitor must identify 
the inline code in order to rewrite it.

Identifying inline JavaScript in HTML files is a complex task. 
Simple search and replace is not satisfactory due to the browser's error tolerant parsing of HTML-code, meaning that the 
browser will make a best-effort attempt to make sense of malformed fragments of 
HTML. It would require the search 
algorithm to account for all parser quirks in regard to malformed HTML;
a task which is at least as complex as actually parsing the document.
This problem is exemplified in Listing~\ref{lst:crazy-html}; the first line
will be interpreted as a script followed by the text \emph{HTML}, the second
line as a script that alerts the string \emph{JavaScript}, and the third will 
display \emph{ac} and \emph{d} in two separate paragraphs and load a script
from an external domain.

\begin{lstlisting}[language=langsmall,label=lst:crazy-html, caption=Example of complicated HTML]
<script>0</script/> HTML </script>
<script>0</script./> alert(JavaScript) </script>
<p>a<sCript/"=/ src=//t.co/abcde a= >b</p></script>c<p>d
\end{lstlisting}


In the web proxy, Mozilla's JavaScript-based HTML-parser \emph{dom.js}~\cite{Mozilla:dom.js}, is used 
to parse the page. The DOM-tree can then be traversed to properly localize 
all inline script code. All occurences of JavaScript code are rewritten as 
outlined in Listing~\ref{lst:wrap-monitor}, wrapped in a call to the monitor.
Because all instances of the modified script code will reference the monitor, 
the monitor must be added as the first script to be executed.


Rewriting JavaScript requires converting the source code to a string, which can 
be fed to the interpreting monitor. The method \lstinline{JSON.stringify()} 
provides this functionality and will properly escape the string to ensure that 
it is semantically equivalent when interpreted by the monitor. The code string is then enclosed in a call to the monitors 
interpreter, as exemplified in Listing~\ref{lst:wrap-monitor}.

\begin{lstlisting}[language=langsmall,label=lst:wrap-monitor, caption=Example of monitor wrapping]
code = 'Monitor.eval(' + JSON.stringify(code) + ')';
\end{lstlisting}




\subsection{Suffix proxy (service)}

%\begin{itemize}
%\item rewrite all or some, can pass configuration through cookie
%\item piggybacking, wildcard DNS
%\item SSL? wildcard certificates? features and drawbacks 
%\item disable SOP, domain relaxing?
%\item DOM parsing to find scripts, compared to regular expressions
%\item difficult to identify all contexts (SVG, CSS and PDF can be rewritten, not flash)
%\item non-standard ports by forwarding all ports to one
%\end{itemize}


%

%Just as the web proxy, the suffix proxy is implemented in NodeJS. 
As mentioned in Section~\ref{sec:arch-suffix}, the web proxy serves as a 
foundation for the suffix proxy, as they share much of the code. The suffix proxy is extended with an additional step of rewriting. 
%The additional rewriting is also related to the wildcard subdomain approach.
%\paragraph{Additional rewriting of HTML}
Since the suffix proxy is referenced by altering the domain name of the target, 
the proxy must ensure that resources associated with the target page are also 
retrieved through the proxy. Resources with URLs relative to the current domain 
requires no processing, as they are relative to the proxy domain and will by 
definition be loaded through the monitor. 
However, the URLs of resources targeting external domains must be rewritten to 
include the proxy domain. Similarly, links to external pages must include the domain of the proxy
for the %user to stay %within the 
monitor%ed %domain 
to apply 
when links are followed.
Apart from the rewriting of inline 
scripts and event handlers done in the web proxy, the suffix proxy must 
identify and rewrite the domain of all such external references. 
The external references are identified in the same manner as inline JavaScript, 
by parsing the HTML to a DOM-tree and traversing the tree. When found, the 
URL is substituted using a regular expression.% in Listing~\ref{lst:reg-exp}.

\todo{Jonas: to be rewritten as Daniel suggested}
Another difference to the web proxy relates to the use of non-standard ports.
The web proxy will receive all requests regardless of the target port. The 
suffix proxy, on the other hand, only listens to the standard ports for HTTP and HTTPS, port 80 and 
443 respectively. The port in a URL is specified in conjunction to, but not included in the domain.
Hence any URLs specifying non-standard ports would attempt to connect to closed 
ports on the proxy server. A solution to this problem is to locally redirect 
all external ports to the standard ports. This is done using \emph{iptables} in Linux, 
Listing~\ref{lst:iptables} shows an example of the command to setup iptables to do this.

\begin{lstlisting}[language=langsmall,label=lst:iptables, caption=Example of redirecting ports using iptables]
iptables -t nat -A PREROUTING -p tcp --dport 1:65535 
	-j REDIRECT --to-ports 80
\end{lstlisting}

\subsection{Integrator}

%\begin{itemize}
%\item- rewrite some, integrator driven, no or limited user configuration
%\item- no need for parsing, integrator decides
%\item- well defined per site policy
%\item- site could allow user to configure policy
%\item- requires developer understanding of the monitor
%\item- future reflection of monitored code?
%\end{itemize}

In line with Section~\ref{sec:arch-integrator}, the integrator is implemented as 
a web page that includes third-party code via the suffix proxy. The monitor is 
manually included in the page, setup and the policies are configured as is 
appropriate for the page. Requesting the third party code through the suffix 
proxy ensures that it will be rewritten to be interpreted and executed by the 
monitor.
%
Part of the code, the untrusted library and any supporting code,
will run inside the monitor, whereas code dealing with sensitive 
information is executed outside the monitor. To make use of the library, 
the trusted code shares only the minimal information required for the 
library to execute. Currently the communication between the trusted and the 
untrusted code is rudimentary. The trusted code can interact with the monitored 
code by evaluating expressions in the monitor, and the result of the computation
is returned to the trusted code.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% 2-3 pages 
\section{Instantiation}
\label{sec:case}

This section presents practical experiments made by instantiating the deployment
methods with the JSFlow~\cite{Hedin:Sabelfeld:CSF12,JSFlow} information-flow monitor. 

\subsection{Monitor}

JSFlow is a dynamic information-flow monitor by tagging values with runtime
security labels used for security decisions. Whenever a potential security
violation has been encountered the monitor stops the execution with a security
error. Suiting our need, the monitor implemented in JavaScript and supports
full non-strict Ecma-262 (v5) including the standard API and large parts of the
browser specific execution environment including the DOM.  From an information
flow perspective, JSFlow supports a wide variety if information flow policies,
including tracking of user input preventing it from leaving the browser used in
the security experiments described below.

\subsection{Experiment scenarios}

Consider the scenario of a password strength checker. The use the service
you input a password and the strength of the password is computed according
to some metric and the result is displayed to the user, typically on a scale
from \emph{weak} to \emph{strong}.
%
For this kind of service confidentiality of the password is of paramount importance --- 
the strength of the password is of no importance if the password is not a secret.
Unless the method of computing strength is a trade secret the service can be
implemented as a client side service, and the password does not have to leave the
browser. Sending back the password to the service provider to perform
the strength computation puts a lot of trust in the service provider to transfer the
password in a secure way, and make sure that no information about the password
is stored. For vital secrets such as passwords, there is no reason for the user
to give this trust; in this situation, it is important to guarantee that
the password does not leave the browser.

We have investigated a number of password strength services. The services can
be categorized based on whether the computation is server side or client side.
Below we report on our results with two services selected from each category. 
Even though it would be conceivable to guarantee security of the client side service
by isolation the service uses Google Analytics, which requires the ability
to communicate over the Internet to function. In general it is not possible
to achieve security via isolation without impairing the functionality of
the service.

The first is the \emph{Testa losenord}~\cite{pts} site provided by
the Swedish authority PTS. The service presents the user with an input field
and a button to initiate the test. Once the button is pressed, the
password is sent to the service provider.

The second is the service the \emph{Check Password Strength}~\cite{GSP} site, providing a pure
client side password strength checker. The user is presented with an
input box, and the strength of the password is computed as the password
is typed in.
%
%It is interesting to note that even if the second service is secure, the input
%field used to input the password is contained in a form. Since the input field
%is not given a name, the password is not included when the form is posted.
%However, the small change of adding a name to the field would cause the
%password to be sent back in cleartext to the service provided rendering the
%service insecure.


For all different deployment methods, loading the page in Firefox causes the monitor
to be used to execute the scripts on the page with the following result.
%
Loading the first site presents the user with the input form and the button.
The user is allowed to type in the password, but as soon as the user presses
the button to perform the check the monitor detects that the password is sent
to the service provider as part of the post data and stops execution with a
security error.
%
Loading the second site presents the user with the input form and the strength
of the password is gradually computed as it is typed. If the user presses enter
the form is posted back to the service provider, but since the password is not
part of the POST data, execution is allowed to continue. 

For these two sites it is possible to envision different security policies. 
For instance, the user might decide to trust PTS based on the fact that it
is an authority, and that the password is sent over HTTPS. At the same time,
the user might want to enforce that the password is not sent back to
\url{getsecurepassword.com}. Even though the password is not sent back in the
current version, a small change would include it in the POST data and
send it in cleartext.

For the browser extension, the user can control the policies without relying on
or trusting other parties, since the extension resides on the user's computer.
For the web proxy, the user has to trust the web proxy provider to honor any
policy decisions. From a corporration perspective, controlling the web proxy
might be beneficial. Even though the user may trust PTS, it is not unreasonable
to assume that a company is interested in enforcing a stricter password regime,
prohibiting passwords from leaving the computer altogether. 
While the suffix proxy provides similar benefits as the web proxy, it also allows 
the user to selectively browse without monitoring. While convenient it also
might open up for security breaches.


\subsection{Performance experiments}
%Jonas

%1 page 
\section{Related work}
\label{sec:related}
We first discuss the original work on reference monitors and their
inlining, then
inlining for secure information flow, 
and, finally,
inlining security checks in the context of
JavaScript.

\paragraph{Inlined reference monitors}
Anderson~\cite{Anderson:72} introduces reference monitors and
outlines the basic principles, recounted in Section~\ref{sec:intro}.
%
Erlingsson and Schneider~\cite{DBLP:conf/nspw/ErlingssonS99,Erlingsson:PhD04} instigate
the area of inlining reference monitors. 
This work studies both enforcement mechanisms and the policies
that they are capable of enforcing, with the focus on safety properties.
Inlined reference monitors
have been proposed in a variety of languages and settings: from
assembly code~\cite{DBLP:conf/nspw/ErlingssonS99} to Java~\cite{DBLP:conf/ecoop/DamJLP09,DBLP:journals/jcs/DamJLP10,DBLP:conf/ccs/DamGL12}.

Ligatti et al. \cite{Ligatti05editautomata:} present a 
general framework for security policies that can
be enforced by monitoring and modifying programs at runtime. 
They introduce \emph{edit automata} that enable
monitors to stop, suppress, and modify the behavior of programs. 



\paragraph{Inlining for secure information flow}
Language-based information-flow security~\cite{Sabelfeld:Myers:JSAC}
features work on inlining monitor for security information flow.
Secure information flow is not
a safety property~\cite{McLean:SSP94}, but can be approximated by
safety properties
(e.g.,~\cite{Boudol:FAST08,Sabelfeld:Russo:PSI09,Austin:Flanagan:PLAS09}).

Chudnov and
Naumann~\cite{Chudnov:Naumann:CSF10} have investigated an inlining
approach to monitoring information flow in a simple imperative language. They inline a flow-sensitive
hybrid monitor by Russo and
Sabelfeld~\cite{Russo:Sabelfeld:CSF10}. The soundness of the inlined
monitor is ensured by bisimulation of the inlined monitor and the
original monitor.

Magazinius et
al.~\cite{Magazinius+:SEC10,DBLP:journals/compsec/MagaziniusRS12} show
how to cope with dynamic code evaluation instructions by inlining
on-the-fly. 
Dynamic code evaluation instructions are
rewritten to make use of auxiliary functions that, when invoked at
runtime, inject security checks into the available string. 
The inlined code manipulates shadow variables to keep track of the
security labels of the program's variables.

However, there are fundamental limits in the scalability of the shadow-variable
approach.  The execution of a vast majority of the JavaScript operations (with
the prime example being the \lstinline{+} operation) is dependent on the types
of their parameters.  This might lead to coercions of the parameters that, in
turn, may invoke such operations as \lstinline{toString} and \lstinline{valueOf}. In order to take
any side effects of these methods into account, any operation that may case
coercions must be wrapped. The end result of this is that the inlined code ends
up emulating the interpreter, leaving no advantages to the shadow-variable
approach.

\paragraph{Inlining for secure JavaScript}
Inlining has been explored for JavaScript, although focusing on
simple properties or preventing against fixed classes of vulnerabilities.
A prominent example in the context of the web is
BrowserShield~\cite{Reis+:TWeb07} by Reis et al. to instrument scripts with
checks for known vulnerabilities.

Yu et al.~\cite{Yu+:POPL07} and Kikuchi et
al.~\cite{DBLP:conf/aplas/2008} present an instrumentation approach
for JavaScript in the browser. Their framework allows instrumented
code to encode edit automata-based policies.

Phung et al.~\cite{DBLP:conf/ccs/PhungSC09} and 
Magazinius et al.~\cite{DBLP:conf/nordsec/MagaziniusPS10} develop
secure wrapping for self-protecting JavaScript. This approach is based
on wrapping built-in JavaScript methods with secure wrappers that
keep track of the security state and regulate access to the original built-ins.  



Agten et al.~\cite{DBLP:conf/acsac/AgtenABPDP12} present JSand, a
server-driven client-side sandboxing framework. The framework mediates
attempts of untrusted code to access to resources in the browser.  
In contrast to its predecessors such as
ConScript~\cite{DBLP:conf/sp/MeyerovichL10}, WebJail~\cite{DBLP:conf/acsac/AckerRDPJ11}, and Contego~\cite{DBLP:conf/trust/LuoD11},
the sandboxing is done purely at JavaScript level, requiring no
browser modification.

Despite the above progress on inlining security checks in JavaScript, achieving
information-flow security for client-side JavaScript by inlining has been out of
reach for the current methods~\cite{Vogt+:NDSS07,DBLP:conf/pldi/ChughMJL09,Yip:Narula:Krohn:Morris:EUROSYS09,Jang+:CCS10,DeGroef+:CCS12}  that either
modify the browser or perform the analysis out-of-the-browser.

%1 page 
\section{Conclusions}
\label{sec:conc}
Different stakeholders have different interests in the security of web
applications. We have presented architectures for inlining security
monitors, to take into account the security goals of the users, system and
network administrators, and service providers and integrators.
%
We achieve great flexibility in the deployment options by considering
security monitors implemented as security-enhanced JavaScript interpreters.
%
The architectures allow deploying such a monitor in a browser
extension, web proxy, or web service.
%
We have reported on the security considerations and on the relative pros and
cons for each architecture.
%
We have applied the architectures to inline an information-flow
security monitor for JavaScript.
%
The security experiments show the
flexibility in supporting the different policies on the sensitive
information from the user. 
%
The performance experiments show reasonable overhead imposed by the
architectures.
% and point out to the relative pros and cons from the
%performance point of view.

Future work is focused on two promising directions. Recall that the
integrator architecture relies on the developer to establish
communication between the monitored and unmonitored code. With the
goal to relieve the integrator from manual efforts, we develop a
framework for secure communication that provides explicit support for
integrating and monitored and unmonitored code.
%
The other direction we pursue is interplay of JavaScript-related
information flows with those caused by other possibilities of running
code in the browser: through Flash, PDF, SVG, and CSS.

\paragraph{Acknowledgments}
This work was funded by 
the European Community under the ProSecuToR and WebSand projects
and
the Swedish research agencies SSF and VR.


% Less than 4 pages 
\bibliographystyle{plain}
\bibliography{literature}
\end{document}
